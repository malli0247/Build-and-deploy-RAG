# Deploying RAG application using AWS Lambda, ECR, Langchain, Huggingface, Docker, in memory or vector databases i.e pinecone 
- AWS lambda- server less service
- AWS ECR to save docker image like in docker hub
- Langchain framework to integrate with huggingface models
- Docker for containerization of code, all dependencies


# Create env
conda create -p llmops python==3.10 -y 

# Activate env
conda activate llmops